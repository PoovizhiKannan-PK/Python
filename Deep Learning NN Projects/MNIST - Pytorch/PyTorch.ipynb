{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 12.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,4])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8933, 0.6481, 0.4321, 0.4775, 0.2517],\n",
      "        [0.2914, 0.6056, 0.6250, 0.7959, 0.3419],\n",
      "        [0.3949, 0.2170, 0.4193, 0.9222, 0.1711],\n",
      "        [0.7422, 0.5179, 0.3757, 0.2042, 0.1776],\n",
      "        [0.8017, 0.8832, 0.1211, 0.2258, 0.7410]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand([5,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8933, 0.6481, 0.4321, 0.4775, 0.2517, 0.2914, 0.6056, 0.6250, 0.7959,\n",
       "         0.3419, 0.3949, 0.2170, 0.4193, 0.9222, 0.1711, 0.7422, 0.5179, 0.3757,\n",
       "         0.2042, 0.1776, 0.8017, 0.8832, 0.1211, 0.2258, 0.7410]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8933, 0.6481, 0.4321, 0.4775, 0.2517],\n",
       "        [0.2914, 0.6056, 0.6250, 0.7959, 0.3419],\n",
       "        [0.3949, 0.2170, 0.4193, 0.9222, 0.1711],\n",
       "        [0.7422, 0.5179, 0.3757, 0.2042, 0.1776],\n",
       "        [0.8017, 0.8832, 0.1211, 0.2258, 0.7410]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8933, 0.6481, 0.4321, 0.4775, 0.2517, 0.2914, 0.6056, 0.6250, 0.7959,\n",
       "         0.3419, 0.3949, 0.2170, 0.4193, 0.9222, 0.1711, 0.7422, 0.5179, 0.3757,\n",
       "         0.2042, 0.1776, 0.8017, 0.8832, 0.1211, 0.2258, 0.7410]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(1,25)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Datasets\n",
    "\n",
    "Training dataset -> used to train the model\n",
    "\n",
    "Test dataset -> dataset unseen by the model used to validate the model\n",
    "\n",
    "If dataset from the training sample is used to test the model, it could lead to overfit in which case the model will work \n",
    "good on insample dataset and will work poverly on out of sample dataset\n",
    "\n",
    "Balanced Dataset -> Before training the model it is crucial to check if the dataset is balanced, ie.,\n",
    "for Example in MNIST dataset, if there is 60% of images with 3 as correct label and 40% of all other numbers, then the model will decide that giving output as 3 will be the shortest route to get high probability of correct answer. So, it is necessary to check if all the classes in a dataset is equally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "#datasets.MNIST(\"\") --> \"\" this quotes tells that the dataset to be saved in the local computer in the same place as the python\n",
    "                        # file. If we want we can specify a specific location in the quotes.\n",
    "    \n",
    "# transforms.ToTensor --> transforms the dataset to a Tensor.\n",
    "\n",
    "\n",
    "test = datasets.MNIST(\"\", train = False, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: \n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: \n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "\n",
    "# this is done to set the loading format of the datasets\n",
    "# batch_size --> We are feeding the model with datch size of 10 inputs, and the model will be optimized each step of the way\n",
    "# the common batch sized differ from 8 to 64. People tend to use base 8. We do this to generalize the input.\n",
    "# shuffle --> shuffle is used the shuffle the input therefore increasing the generalization property of the neural network\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 8, 3, 6, 9, 3, 3, 0, 3, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# So the above \"data\" printed out first batch of the train dataset. \n",
    "# It gave two tensors. First tensor is the pixels of image, second tensor is the label of what the image represents\n",
    "\n",
    "x, y = data[0][0], data[1][0] # So here, we are accesing the 0th index image from 0th tensor data[0][0] and 0th index label \n",
    "                              # from first index tensor data[1][0]\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725,\n",
      "          0.8745, 0.9961, 0.7137, 0.8235, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.9765, 0.6039, 0.6078, 0.4863, 0.0196, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5373,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.7255, 0.0118, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4706,\n",
      "          0.9922, 0.9922, 0.9922, 0.7529, 0.7373, 0.7373, 0.7373, 0.7373,\n",
      "          0.7373, 0.7373, 0.9647, 0.9922, 0.9922, 0.2510, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
      "          0.6392, 0.6706, 0.1333, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.8784, 0.9922, 0.9961, 0.2510, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3059, 0.9569, 0.9922, 0.8980, 0.0784, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3020, 0.9647, 0.9922, 0.9569, 0.4510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3059,\n",
      "          0.9529, 0.9922, 0.9922, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6039, 0.9725,\n",
      "          0.9922, 0.9490, 0.4549, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.9490, 0.9922,\n",
      "          0.9725, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.9922, 0.9922, 0.9922,\n",
      "          0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.9922, 0.9922, 0.9922,\n",
      "          0.9059, 0.5412, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1412, 0.8902, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.6275, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.6235, 0.7882,\n",
      "          0.9608, 0.9922, 0.9922, 0.6078, 0.0353, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1922, 0.9922, 0.9922, 0.9922, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588,\n",
      "          0.7647, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0627, 0.9922, 0.9961, 0.9922, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9569,\n",
      "          0.9922, 0.3647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745,\n",
      "          0.5059, 0.9922, 0.9922, 0.7725, 0.0235, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
      "          0.8784, 0.1686, 0.0000, 0.0000, 0.0000, 0.0275, 0.3020, 0.6392,\n",
      "          0.9922, 0.9922, 0.9804, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9922,\n",
      "          0.9922, 0.9647, 0.7412, 0.7412, 0.7412, 0.7922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8471,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922, 0.9529,\n",
      "          0.7961, 0.3216, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863,\n",
      "          0.7176, 0.9922, 0.9922, 0.9922, 0.9922, 0.7608, 0.6000, 0.3098,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape) # This shape is not a image. In MNIST dataset, Image would be of shape 28 * 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#So,\n",
    "\n",
    "plt.imshow(x.view(28,28))  # we are using view() function on the \"x\". view() in torch is similar to reshape() function in numpy\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5923\n",
      "1 6742\n",
      "2 5958\n",
      "3 6131\n",
      "4 5842\n",
      "5 5421\n",
      "6 5918\n",
      "7 6265\n",
      "8 5851\n",
      "9 5949\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    for data in trainset:\n",
    "        for j in range(0,10):\n",
    "            if i == data[1][j]:\n",
    "                counter += 1;\n",
    "    print(i, counter)\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   5923\n",
      "1   6742\n",
      "2   5958\n",
      "3   6131\n",
      "4   5842\n",
      "5   5421\n",
      "6   5918\n",
      "7   6265\n",
      "8   5851\n",
      "9   5949\n",
      "\n",
      " 60000\n"
     ]
    }
   ],
   "source": [
    "counter = [0] * 10\n",
    "\n",
    "for data in trainset:\n",
    "    for i in range(0, 10):   # The reason for range 10 is, batch_size in dataloader is 10. So input is loaded for each iteration\n",
    "        counter[data[1][i]] += 1\n",
    "#print(counter)\n",
    "\n",
    "total = 0\n",
    "for i in range(0,10):          \n",
    "    print(i, ' ',counter[i])\n",
    "    total += counter[i]\n",
    "\n",
    "print('\\n', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  9.87\n",
      "1 :  11.24\n",
      "2 :  9.93\n",
      "3 :  10.22\n",
      "4 :  9.74\n",
      "5 :  9.04\n",
      "6 :  9.86\n",
      "7 :  10.44\n",
      "8 :  9.75\n",
      "9 :  9.92\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(i, ': ', round((counter[i]/total)*100, 2))  \n",
    "    \n",
    "# This is a pretty balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn    #More like OOP i.e., with class. Here intialize and use the class and its methods.\n",
    "import torch.nn.functional as F  #Here we just use a specific funtion. Here we pass parameter to a specific function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# FC1 sctands for Fully connected layer. nn.Liner(input, output) method takes input and \n",
    "# output as argumets. Here input is flatend 28*28 image i.e., 784 pixels in a row.\n",
    "# Our output is going to be 64 neuron hidden layer. We are going to use 3 hideen layers\n",
    "\n",
    "#So in the below init method, we have and input which is 28*28, three hidden layers that take 64 inputs and give 64 output\n",
    "#neurons and last layer which has 10 output because there are 10 classes.\n",
    "\n",
    "class Net(nn.Module):                   # class Net inherits the class nn.Modeule\n",
    "    \n",
    "    def __init__(self):                 # defining a __init__ method\n",
    "        super().__init__()              # runs the _-init__ method in the nn.Module class.\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)   \n",
    "        self.fc3 = nn.Linear(64, 64)   \n",
    "        self.fc4 = nn.Linear(64, 10)   # input 28*28 output 64 neurons-->ip 64 op 64-->ip 64 op 64-->ip 64 op 10 neurons\n",
    "    \n",
    "    def forward(self, x):              # Feed Forward Funtion. We are going to define how the data flow through the layers\n",
    "        x = F.relu(self.fc1(x))        # F.relu() whoch stands for Rectified Linear is the activation Function\n",
    "        x = F.relu(self.fc2(x))        # Activation function runs on Op layer. We run it only on the hidden layers.\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1)   # log_softmax() is used to give a distribution in the Op. dimension = 1 for linear layers\n",
    "        \n",
    "net = Net()    #Object of Net() class.\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28)        # -1 means saying don't worry about the input amount, it can be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4052, -2.2858, -2.3652, -2.3787, -2.1316, -2.4560, -2.1327, -2.2984,\n",
       "         -2.2939, -2.3307]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4062, -2.2996, -2.3658, -2.3927, -2.1344, -2.4310, -2.1415, -2.3025,\n",
       "         -2.2726, -2.3281]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss: Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients. And gradients are used to update the weights of the Neural Net.\n",
    "\n",
    "Optimizer: Optimizers are algorithms or methods used to change the attributes of the neural network such as weights and learning rate to reduce the losses based on the losses calculated. Optimizers are used to solve optimization problems by minimizing the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) # lr means learning rate\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(3):                # 3 full passes over the data\n",
    "    for data in trainset:             # `data` is a batch of featuresets and labels\n",
    "        X, y = data                   # X is the batch of features, y is the batch of targets i.e., labels.\n",
    "        net.zero_grad()               # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1, 28*28))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()               # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()              # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)                       # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.966\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([7, 8, 1, 9, 2, 2, 4, 2, 2, 0]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[3].view(-1, 784))[0]))  #3rd index is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
